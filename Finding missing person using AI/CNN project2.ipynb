{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential #used to initialize model\n",
    "from tensorflow.keras.layers import Dense #used to add layers\n",
    "from tensorflow.keras.layers import Conv2D#convolution Layer\n",
    "from tensorflow.keras.layers import MaxPool2D #max pooling\n",
    "from tensorflow.keras.layers import Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step2:Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step3: Adding Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D( 32,3,3,input_shape=(64,64,3),activation='relu'))\n",
    "#1st param in conv2D = no of feature detectors(or say feature detector matrix) to form feature map\n",
    "#2nd,3rd param = size of feat.Detect(or say feature detector matrix size ie,. 3 X 3 here )\n",
    "#4th param = Expected image input shape(every img sould be of same size so here 64 X 64 and 3 means its an RGB img (2 means grayscale img and 1 for binary img(black and white))\n",
    "#5th param= Activation fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Adding max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2))) # 2,2 rep size of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D( 32,3,3,input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2))) # 2,2 rep size of matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#step5: Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())#converts ndim to 1 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 21, 21, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 10,144\n",
      "Trainable params: 10,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step6: ANN layers (Full connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128,activation='relu',kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(units=128,activation='relu',kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=3,activation='softmax',kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 21, 21, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 14,755\n",
      "Trainable params: 14,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen= ImageDataGenerator(rescale=1./255,shear_range=0.2,horizontal_flip=True,zoom_range=0.2)\n",
    "test_datagen= ImageDataGenerator(rescale=1./255)\n",
    "#normalizing steps.........\n",
    "#rescale will change the pixel values into the range of 0 and 1 \n",
    "#shear_range is used to drag the image to one cornor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r'dataset3\\Train',target_size=(64,64),batch_size=32,class_mode='categorical')\n",
    "x_test=train_datagen.flow_from_directory(r'dataset3\\Test',target_size=(64,64),batch_size=32,class_mode='categorical')\n",
    "#more than 2 categories class_mode='categorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Isha': 0, 'Rishabh': 1, 'Riya': 2}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 90s 11s/step - loss: 1.0987 - accuracy: 0.3375 - val_loss: 1.0969 - val_accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 1.0940 - accuracy: 0.4083 - val_loss: 1.0924 - val_accuracy: 0.4667\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 58s 7s/step - loss: 1.0886 - accuracy: 0.3875 - val_loss: 1.0847 - val_accuracy: 0.4333\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 70s 9s/step - loss: 1.0642 - accuracy: 0.5250 - val_loss: 1.0643 - val_accuracy: 0.5500\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 76s 10s/step - loss: 1.0269 - accuracy: 0.5500 - val_loss: 0.9838 - val_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 69s 9s/step - loss: 0.9513 - accuracy: 0.5167 - val_loss: 1.0131 - val_accuracy: 0.4667\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 61s 8s/step - loss: 0.9756 - accuracy: 0.4625 - val_loss: 0.9224 - val_accuracy: 0.5667\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 50s 6s/step - loss: 0.8830 - accuracy: 0.5875 - val_loss: 0.9363 - val_accuracy: 0.6167\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.8458 - accuracy: 0.6333 - val_loss: 0.7712 - val_accuracy: 0.6500\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 54s 7s/step - loss: 0.7884 - accuracy: 0.6250 - val_loss: 0.8175 - val_accuracy: 0.6333\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 62s 8s/step - loss: 0.8081 - accuracy: 0.6500 - val_loss: 0.7935 - val_accuracy: 0.5833\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 54s 7s/step - loss: 0.6938 - accuracy: 0.6667 - val_loss: 0.7334 - val_accuracy: 0.7333\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 58s 7s/step - loss: 0.7030 - accuracy: 0.7042 - val_loss: 0.6940 - val_accuracy: 0.7333\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 52s 7s/step - loss: 0.6617 - accuracy: 0.7583 - val_loss: 0.6710 - val_accuracy: 0.7333\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 55s 7s/step - loss: 0.6396 - accuracy: 0.7917 - val_loss: 0.6696 - val_accuracy: 0.6167\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 54s 7s/step - loss: 0.6227 - accuracy: 0.7875 - val_loss: 0.6768 - val_accuracy: 0.6833\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.5503 - accuracy: 0.8000 - val_loss: 0.5642 - val_accuracy: 0.8833\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 55s 7s/step - loss: 0.5496 - accuracy: 0.7917 - val_loss: 0.7561 - val_accuracy: 0.6333\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 58s 7s/step - loss: 0.6136 - accuracy: 0.7167 - val_loss: 0.5937 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 51s 6s/step - loss: 0.6389 - accuracy: 0.7208 - val_loss: 0.7434 - val_accuracy: 0.6333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e008845130>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,steps_per_epoch=240//30,validation_data=x_test,epochs=20,validation_steps=60//30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model-bw.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model-bw.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
